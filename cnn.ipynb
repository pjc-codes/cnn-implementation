{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67264f50",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Implementation\n",
    "\n",
    "We build and implement convolutional neural networks (CNNs) to classify MNIST images of handwritten digits.\n",
    "\n",
    "We use the following implementations:\n",
    "\n",
    "- Tensorflow and Keras\n",
    "  - Subclassing `tf.keras.models.Model`\n",
    "  - Keras Functional APIs\n",
    "- Pytorch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958abfb",
   "metadata": {},
   "source": [
    "**Dataset: MNIST**\n",
    "\n",
    "MNIST consists of grayscale images of handwritten digits (0–9):\n",
    "\n",
    "- Image size: 28 × 28\n",
    "- Channels: 1 (grayscale)\n",
    "- Classes: 10\n",
    "\n",
    "**Model Architecture**\n",
    "\n",
    "The CNN architecture we use follows the standard conceptual pattern of CNNs:\n",
    "\n",
    "1. Convolutional feature extraction\n",
    "\n",
    "    - Small 3×3 filters detect local patterns (edges, corners)\n",
    "    - Feature depth increases as representations become more abstract\n",
    "\n",
    "2. Spatial downsampling\n",
    "\n",
    "    - 2×2 max pooling reduces resolution\n",
    "    - Helps with translation invariance and parameter efficiency\n",
    "\n",
    "3. Dense classification head\n",
    "\n",
    "    - Flattened feature maps are mapped to a low-dimensional representation\n",
    "    - Dropout is used to reduce overfitting\n",
    "    - Final layer outputs one score per class\n",
    "\n",
    "**Summary of CNN Architecture**\n",
    "\n",
    "- Input: 28 × 28 × 1\n",
    "- Conv block 1: 32 filters → max pooling\n",
    "- Conv block 2: 64 filters → max pooling\n",
    "- Dense layer: 128 units + ReLU\n",
    "- Dropout: 0.5\n",
    "- Output: 10 class scores (logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0473b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a29867",
   "metadata": {},
   "source": [
    "## Implementation by Subclassing `tf.keras.models.Model`\n",
    "\n",
    "Subclassing `Model` (instead of using `Sequential`) gives you:\n",
    "\n",
    "- Full control over the forward pass (call)\n",
    "\n",
    "- Explicit handling of training vs inference\n",
    "\n",
    "- Easier extension to more complex architectures\n",
    "\n",
    "This is the recommended approach for anything non-trivial in terms of neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a16d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjc/Desktop/cnn-implementation/.venv/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "tf.random.set_seed(69)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# MNIST data comes as (N, 28, 28); we need to add the channel dimension for CNN to work\n",
    "x_train = x_train[..., tf.newaxis]  # (N, 28, 28, 1)\n",
    "x_test = x_test[..., tf.newaxis]  # (N, 28, 28, 1)\n",
    "\n",
    "# normalization\n",
    "x_train = (x_train/ 255.0).astype(\"float32\")\n",
    "x_test = (x_test/ 255.0).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e974169",
   "metadata": {},
   "source": [
    "We load the dataset and then add a channel dimension to it because convolutional layers works with arrays of shape `(m, h, w, c)`. We also normalize the data by dividing by `255.0` which is the maximum possible value where as `0.0` is the least possible value.\n",
    "\n",
    "Now we define the CNN neural architecture that we will use in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "#  model architecture\n",
    "# ---------------------\n",
    "\n",
    "class ConvNet(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__() # mandatory call to parent class constructor\n",
    "\n",
    "        # first convolutional block - 3x3x32 filter + relu + 2x2 maxpool\n",
    "        self.conv1 = Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            name=\"Conv1\"\n",
    "        )\n",
    "        self.pool1 = MaxPooling2D(pool_size=2, strides=2)\n",
    "\n",
    "        # second convolutional block - 3x3x64 filter + relu + 2x2 maxpool\n",
    "        self.conv2 = Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            name=\"Conv2\"\n",
    "        )\n",
    "        self.pool2 = MaxPooling2D(pool_size=2, strides=2)\n",
    "\n",
    "        # fully connected layers - 128 neurons + relu + dropout + 10 neurons (logits)\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = Dense(128, activation=\"relu\", name=\"FC1\")\n",
    "        self.dropout = Dropout(0.5, name=\"Dropout\") # dropout layer for regularization\n",
    "        self.fc2 = Dense(10, name=\"Logits_Output\")  # logits are the outputs\n",
    "        \n",
    "\n",
    "    def call(self, x, training=False): # invoked during training aswell as inference\n",
    "        # 28x28x1 -> 14x14x32\n",
    "        x = self.pool1(self.conv1(x))\n",
    "\n",
    "        # 14x14x32 -> 7x7x64\n",
    "        x = self.pool2(self.conv2(x))\n",
    "\n",
    "        # 7x7x64 -> 3136\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb97e75",
   "metadata": {},
   "source": [
    "Here's a breakdown of the various components: \n",
    "\n",
    "1. Convolution Layer `Conv2D()`:\n",
    "\n",
    "   - `filters=32` \n",
    "     - You learn 32 different feature maps\n",
    "     - Each filter has shape (3, 3, in_channels)\n",
    "\n",
    "   - `kernel_size=3` \n",
    "     - Means a 3×3 spatial kernel\n",
    "     - padding=\"same\"\n",
    "       - Output spatial size is preserved\n",
    "       - For a 28×28 input, output remains 28×28\n",
    "   - `activation=\"relu\"`\n",
    "     - Applies ReLU inside the layer\n",
    "     - Equivalent to `Conv2D(...)` followed by `ReLU()` in terms of Keras Layers.\n",
    "   - `name=\"Conv1\"`\n",
    "     - Optional, but useful for:\n",
    "       - Model summaries\n",
    "       - Debugging\n",
    "       - Loading weights\n",
    "\n",
    "2. `MaxPooling2D()` defines a max-pooling layer.\n",
    "\n",
    "   - `pool_size=2`\n",
    "     - Uses a 2×2 window\n",
    "   - `strides=2`\n",
    "     - Moves the window by 2 pixels\n",
    "\n",
    "   The effect of it is that:\n",
    "   - Spatial dimensions are halved: 28×28 → 14×14\n",
    "   - Channels are unchanged.\n",
    "\n",
    "3. `Dropout(0.5)` randomly sets 50% of activations to zero during training.\n",
    "   - Purpose: \n",
    "     - Regularization \n",
    "     - Reduces co-adaptation \n",
    "     - Helps prevent overfitting\n",
    "   - Dropout does nothing during inference.\n",
    "  \n",
    "4. Forward pass (the `call` method) defines the forward computation.\n",
    "\n",
    "   - `training` flag is crucial: \n",
    "     - `True` → training mode \n",
    "     - `False` → inference mode\n",
    "\n",
    "   - Keras sets this automatically when calling: \n",
    "     - `model.fit()` → `training=True`\n",
    "     - `model.predict()` → `training=False`\n",
    "\n",
    "1. Other points to note:\n",
    "   - The model is trained using logits (no softmax in the final layer) for numerical stability.\n",
    "   - Softmax is applied only when converting logits to probabilities at inference time.\n",
    "   - The code is intended for learning and experimentation, not production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8e65c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.8220 - loss: 0.5868 - val_accuracy: 0.9578 - val_loss: 0.1362\n",
      "Epoch 2/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9517 - loss: 0.1614 - val_accuracy: 0.9770 - val_loss: 0.0801\n",
      "Epoch 3/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9676 - loss: 0.1075 - val_accuracy: 0.9818 - val_loss: 0.0624\n",
      "Epoch 4/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9727 - loss: 0.0882 - val_accuracy: 0.9847 - val_loss: 0.0527\n",
      "Epoch 5/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.9788 - loss: 0.0715 - val_accuracy: 0.9859 - val_loss: 0.0461\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0374\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0360\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# setting up and training the model\n",
    "# ---------------------------------\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history=model.fit(\n",
    "    x_train,y_train,\n",
    "    epochs=5,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "training_loss, training_accuracy =model.evaluate(x_train, y_train)\n",
    "test_loss, test_accuracy =model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d617c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.03741063177585602, Training Accuracy: 0.9884333610534668\n",
      "Test Loss: 0.035951100289821625, Test Accuracy: 0.9879000186920166\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Loss: {training_loss}, Training Accuracy: {training_accuracy}\")\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa01f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"conv_net\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"conv_net\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FC1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Logits_Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FC1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m401,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Logits_Output (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,928</span> (4.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,264,928\u001b[0m (4.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,642</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,642\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">843,286</span> (3.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m843,286\u001b[0m (3.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac97137",
   "metadata": {},
   "source": [
    "## Implementation using Functional APIs\n",
    "\n",
    "We can implement the same using Functional API of keras. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911d4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.8146 - loss: 0.5975 - val_accuracy: 0.9582 - val_loss: 0.1416\n",
      "Epoch 2/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9486 - loss: 0.1735 - val_accuracy: 0.9771 - val_loss: 0.0785\n",
      "Epoch 3/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9650 - loss: 0.1169 - val_accuracy: 0.9822 - val_loss: 0.0607\n",
      "Epoch 4/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9733 - loss: 0.0886 - val_accuracy: 0.9847 - val_loss: 0.0516\n",
      "Epoch 5/5\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.9782 - loss: 0.0745 - val_accuracy: 0.9862 - val_loss: 0.0461\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0377\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0359\n",
      "Training Loss: 0.037733983248472214, Training Accuracy: 0.988349974155426\n",
      "Test Loss: 0.0359133742749691, Test Accuracy: 0.9878000020980835\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D,\n",
    "    Flatten, Dense, Dropout\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1), name=\"Input\")\n",
    "\n",
    "# First convolutional block\n",
    "x = Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "    name=\"Conv1\"\n",
    ")(inputs)\n",
    "x = MaxPooling2D(pool_size=2, strides=2, name=\"Pool1\")(x)\n",
    "\n",
    "# Second convolutional block\n",
    "x = Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "    name=\"Conv2\"\n",
    ")(x)\n",
    "x = MaxPooling2D(pool_size=2, strides=2, name=\"Pool2\")(x)\n",
    "\n",
    "# Fully connected layers\n",
    "x = Flatten(name=\"Flatten\")(x)\n",
    "x = Dense(128, activation=\"relu\", name=\"FC1\")(x)\n",
    "x = Dropout(0.5, name=\"Dropout\")(x)\n",
    "\n",
    "# Output layer — logits\n",
    "outputs = Dense(10, name=\"Logits\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"ConvNet\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "training_loss, training_accuracy = model.evaluate(x_train, y_train)\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Training Loss: {training_loss}, Training Accuracy: {training_accuracy}\")\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e30e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ConvNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ConvNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FC1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv1 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Conv2 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ FC1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m401,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Logits (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,264,928</span> (4.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,264,928\u001b[0m (4.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,642</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,642\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">843,286</span> (3.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m843,286\u001b[0m (3.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476985b",
   "metadata": {},
   "source": [
    "# Implementation using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # neural-network module namespace\n",
    "import torch.optim as optim # optimization algorithms\n",
    "from torchvision import (\n",
    "    datasets, # for loading datasets\n",
    "    transforms # data transformations - preprocessing\n",
    "    ) \n",
    "from torch.utils.data import DataLoader # for data batching, shuffling, etc\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):  # custom neural network module inheriting from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__() # base class constructor for initializing parameters etc\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # first conv block: conv + relu + maxpool\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # second conv block: conv + relu + maxpool\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657d501",
   "metadata": {},
   "source": [
    "`self.features` block converts **raw images → spatial features**.\n",
    "\n",
    "Let’s track shapes assuming MNIST input:\n",
    "\n",
    "* Input shape: `(N, 1, 28, 28)`. Note that we had `(N, 28, 28, 1)`  earlier in tensorflow. \n",
    "\n",
    "The first convolution layer has the following:\n",
    "\n",
    "* 1 input channel (grayscale)\n",
    "* 32 output channels (learned feature maps)\n",
    "* `padding=1` preserves spatial size\n",
    "\n",
    "And the output is : (N, 32, 28, 28)\n",
    "\n",
    "Then the ReLU component:\n",
    "\n",
    "* Applies `max(0, x)`\n",
    "* `inplace=True` saves memory by modifying tensor directly\n",
    "\n",
    "Followed by pooling which:\n",
    "\n",
    "* Downsamples by factor of 2\n",
    "* Takes `max` over 2×2 windows\n",
    "\n",
    "The output is: `(N, 32, 14, 14)`\n",
    "\n",
    "Similarly, the second convolution block:\n",
    "\n",
    "* Doubles channel depth\n",
    "* Keeps spatial size due to padding\n",
    "\n",
    "Meaning that after conv + ReLU the output shape is : `(N, 64, 14, 14)`\n",
    "\n",
    "After pooling the output shape is : `(N, 64, 7, 7)`\n",
    "\n",
    "At this point, the network has extracted 64 feature maps, each `7×7`.\n",
    "\n",
    "\n",
    "The fully connected part acts as the classifier:\n",
    "\n",
    "This block maps the extracted features → class scores.\n",
    "\n",
    "Flatten reshapes `(N, 64, 7, 7) → (N, 3136 = 64*7*7)`\n",
    "\n",
    "Then we have a first dense layer which linearly maps `3136 → 128` and is followed by ReLU.\n",
    "\n",
    "Then we use Dropout that:\n",
    "\n",
    "* Randomly zeroes 50% of activations during training\n",
    "* Acts as regularization\n",
    "* Disabled automatically during inference `model.eval()`\n",
    "\n",
    "The output layer:\n",
    "* Outputs 10 raw scores\n",
    "* One score per digit class (0–9)\n",
    "* These are logits, not probabilities. This is intentional and correct for `CrossEntropyLoss`.\n",
    "\n",
    "The `forward` pass function:\n",
    "\n",
    "* Defines how input flows through the network\n",
    "* PyTorch’s autograd builds the computation graph automatically\n",
    "\n",
    "No softmax here — also intentional (more on that below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - loss: 0.4185\n",
      "Epoch 2/5 - loss: 0.1148\n",
      "Epoch 3/5 - loss: 0.0839\n",
      "Epoch 4/5 - loss: 0.0671\n",
      "Epoch 5/5 - loss: 0.0568\n"
     ]
    }
   ],
   "source": [
    "# training function definition\n",
    "\n",
    "def train_model( \n",
    "    epochs=5,\n",
    "    batch_size=64, \n",
    "    lr=1e-3,\n",
    "    device=None # only relevant for GPU systems\n",
    "):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()]) # data preprocessing\n",
    "\n",
    "    # loading the MNIST training dataset\n",
    "    train_dataset = datasets.MNIST(\n",
    "        root=\"./data\",\n",
    "        train=True, # loads test set when False\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    ) # returns (image, label) pairs\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True # shuffling for better training\n",
    "    ) # returns iterable pairs (batch of images, batch of labels)\n",
    "\n",
    "    model = ConvNet().to(device) # move model to the appropriate device (CPU/GPU)\n",
    "    criterion = nn.CrossEntropyLoss() # loss function for multi-class classification, requires logits\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # Adam optimizer\n",
    "\n",
    "    model.train() # set model to training mode, activates dropout layers, etc.\n",
    "\n",
    "    for epoch in range(epochs): # epoch loop\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch_data, _batch_target in train_loader: # batch loop\n",
    "            # batch_data: (batch_size, 1, 28, 28), _batch_target: (batch_size,)\n",
    "            batch_data = batch_data.to(device) \n",
    "            _batch_target = _batch_target.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # clear previous gradients\n",
    "            output = model(batch_data) # forward pass to get logits\n",
    "            loss = criterion(output, _batch_target) # compute loss\n",
    "            loss.backward() # backpropagation to compute gradients\n",
    "            optimizer.step() # update model parameters\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model # return the trained model\n",
    "\n",
    "# training the model\n",
    "trained_model = train_model(batch_size=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c783ef5",
   "metadata": {},
   "source": [
    "Here is an alternative but far more complicated PyTorch implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc53fb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.6088\n",
      "Epoch 1, Batch 200, Loss: 0.1822\n",
      "Epoch 2, Batch 100, Loss: 0.1168\n",
      "Epoch 2, Batch 200, Loss: 0.0948\n",
      "Epoch 3, Batch 100, Loss: 0.0754\n",
      "Epoch 3, Batch 200, Loss: 0.0802\n",
      "Epoch 4, Batch 100, Loss: 0.0609\n",
      "Epoch 4, Batch 200, Loss: 0.0680\n",
      "Epoch 5, Batch 100, Loss: 0.0517\n",
      "Epoch 5, Batch 200, Loss: 0.0509\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn # neural-network module namespace\n",
    "import torch.optim as optim # optimization algorithms\n",
    "from torchvision import (\n",
    "    datasets, # for loading datasets\n",
    "    transforms # data transformations - preprocessing\n",
    "    ) \n",
    "from torch.utils.data import DataLoader # used for batching, shuffling etc\n",
    "\n",
    "# defining the CNN architecture\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # convolutional block - 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, \n",
    "                               kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # convolutional block - 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, \n",
    "                               kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional block - 1: 28x28x1 -> 14x14x32\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # convolutional block - 2: 14x14x32 -> 7x7x64\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # flattening: 7x7x64 -> 3136\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# training setup\n",
    "def train_model():\n",
    "    # data preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # load mnist dataset\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, \n",
    "                                   download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    \n",
    "    # initialize model, loss, and optimizer\n",
    "    model = ConvNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (batch_data, batch_target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(batch_data)\n",
    "            loss = criterion(output, batch_target)\n",
    "            \n",
    "            # backward pass and optimization\n",
    "            loss.backward() # backpropagation to compute gradients\n",
    "            optimizer.step() # update model parameters\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 99:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx+1}, '\n",
    "                      f'Loss: {running_loss/100:.4f}')\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    return model\n",
    "\n",
    "# run training\n",
    "trained_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b0bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-implementation (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
